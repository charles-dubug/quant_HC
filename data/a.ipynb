{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上証指數\n",
    "import akshare as ak\n",
    "\n",
    "#shenzhen\n",
    "\n",
    "stock_szse_summary_df = ak.stock_szse_summary(date=\"20250221\")\n",
    "print(stock_szse_summary_df)\n",
    "\n",
    "\n",
    "#shanghai \n",
    "stock_sse_summary_df = ak.stock_szse_summary(date=\"20250221\")\n",
    "print(stock_sse_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "# 获取东方财富网的概念板块数据\n",
    "\n",
    "industry_board_df = ak.stock_board_industry_name_em()\n",
    "\n",
    "industry_board_df.to_csv(r\"C:\\Quant\\quant_HC\\data\\stocks\\industry_board_df.csv\", index=False)\n",
    "print(industry_board_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "# 检查 akshare 版本（需 >= 1.10.0）\n",
    "print(\"akshare 版本:\", ak.__version__)\n",
    "\n",
    "# 获取概念板块数据\n",
    "try:\n",
    "    df = ak.stock_board_concept_name_em()\n",
    "    print(\"前5行数据示例:\\n\", df.head())\n",
    "    print(\"\\n列名检查:\", df.columns.tolist())\n",
    "    \n",
    "    # 检查关键字段是否有有效数据\n",
    "    if df[\"涨跌幅\"].sum() == 0:\n",
    "        print(\"警告：涨跌幅全为0，可能未在交易时段运行！\")\n",
    "except Exception as e:\n",
    "    print(\"接口调用失败，错误信息:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "stock_zh_a_spot_em_df = ak.stock_zh_a_spot_em()\n",
    "print(stock_zh_a_spot_em_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "# Fetch the stock data\n",
    "stock_zh_a_spot_em_df = ak.stock_zh_a_spot_em()\n",
    "\n",
    "# Save the DataFrame to a CSV file (corrected file path)\n",
    "stock_zh_a_spot_em_df.to_csv(r\"C:\\Quant\\quant_HC\\data\\stocks\\stock_zh_a_spot_em.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been saved as 'stock_zh_a_spot_em.csv' in the specified directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 综合筛选大资金流入候选股\n",
    "candidates = stock_zh_a_spot_em_df[\n",
    "    (stock_zh_a_spot_em_df[\"量比\"] > 2) &\n",
    "    (stock_zh_a_spot_em_df[\"换手率\"] > 15) &\n",
    "    (stock_zh_a_spot_em_df[\"涨跌幅\"] > 5) &\n",
    "    (stock_zh_a_spot_em_df[\"成交额\"] > 5e8)\n",
    "]\n",
    "\n",
    "print(\"大资金流入候选股：\")\n",
    "print(candidates[[\"代码\", \"名称\", \"最新价\", \"涨跌幅\", \"换手率\", \"量比\", \"成交额\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 综合筛选大资金流入候选股\n",
    "candidates_2 = stock_zh_a_spot_em_df[\n",
    "    (stock_zh_a_spot_em_df[\"涨跌幅\"] > 5)\n",
    "]\n",
    "\n",
    "print(\"大资金流入候选股：\")\n",
    "print(candidates_2[[\"代码\", \"名称\", \"最新价\", \"涨跌幅\", \"换手率\", \"量比\", \"成交额\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = r\"C:\\Quant\\quant_HC\\data\\stocks\\stock_zh_a_spot_em.csv\"\n",
    "stock_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "# 综合筛选大资金流入候选股\n",
    "candidates_1 = stock_df[\n",
    "    (stock_df[\"量比\"] > 2) &\n",
    "    (stock_df[\"换手率\"] > 15) &\n",
    "    (stock_df[\"成交额\"] > 5e8)\n",
    "]\n",
    "\n",
    "print(\"大资金流入候选股：\")\n",
    "print(candidates_1[[\"代码\", \"名称\", \"最新价\", \"涨跌幅\", \"换手率\", \"量比\", \"成交额\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将 '代码' 列转换为字符串类型\n",
    "candidates_1[\"代码\"] = candidates_1[\"代码\"].astype(str)\n",
    "candidates_2[\"代码\"] = candidates[\"代码\"].astype(str)\n",
    "\n",
    "# 通过 '代码' 列进行合并\n",
    "common_df = pd.merge(candidates_1, candidates, on=\"代码\", how=\"inner\")\n",
    "\n",
    "# 打印重合的行\n",
    "print(\"重合的股票：\")\n",
    "print(common_df[[\"代码\", \"名称_x\", \"最新价_x\", \"涨跌幅_x\", \"换手率_x\", \"量比_x\", \"成交额_x\"]])\n",
    "\n",
    "# 打印重合的股票代码\n",
    "common_codes = common_df[\"代码\"].unique()\n",
    "print(f\"\\n重合的股票代码：{common_codes}\")\n",
    "\n",
    "# 如果没有重合\n",
    "if common_df.empty:\n",
    "    print(\"\\n两个 DataFrame 之间没有重合的股票。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "# 获取指数日线数据（示例：上证指数 sh000001）\n",
    "symbol = \"sh000001\"\n",
    "index_daily = ak.stock_zh_index_daily(symbol=symbol)\n",
    "\n",
    "# 计算每日涨跌幅（收盘价相对于前一日的涨跌百分比）\n",
    "index_daily['涨跌幅'] = index_daily['close'].pct_change() * 100\n",
    "\n",
    "# 获取最新交易日尾盘（收盘）涨跌幅\n",
    "latest_change = index_daily['涨跌幅'].iloc[-1]\n",
    "print(f\"最新交易日收盘涨跌幅: {latest_change:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 定义主要指数代码（格式：akshare 兼容的代码）\n",
    "index_list = {\n",
    "    \"上证指数\": \"sh000001\",\n",
    "    \"沪深300\": \"sh000300\",\n",
    "    \"深证成指\": \"sz399001\",\n",
    "    \"创业板指\": \"sz399006\",\n",
    "    \"科创50\": \"sh000688\"\n",
    "}\n",
    "\n",
    "def get_index_last_30min_change(symbol: str) -> float:\n",
    "    \"\"\"获取指数最后30分钟涨幅（基于分钟数据）\"\"\"\n",
    "    try:\n",
    "        # 获取分钟级数据（周期为1分钟）\n",
    "        minute_data = ak.stock_board_concept_hist_min_em(symbol=\"上证指数\", period=\"30\")\n",
    "\n",
    "        minute_data['日期时间'] = pd.to_datetime(minute_data['日期时间'])\n",
    "        \n",
    "        # 筛选交易日的最后30分钟（14:30-15:00）\n",
    "        last_date = minute_data['日期时间'].max().date()  # 最新日期\n",
    "        mask = (minute_data['日期时间'] >= pd.Timestamp(last_date).replace(hour=14, minute=30)) & \\\n",
    "               (minute_data['日期时间'] <= pd.Timestamp(last_date).replace(hour=15, minute=0))\n",
    "        last_30min_data = minute_data[mask]\n",
    "        \n",
    "        if last_30min_data.empty:\n",
    "            return 0.0\n",
    "        \n",
    "        # 计算涨幅：起始价（14:30的收盘价）到结束价（15:00的收盘价）\n",
    "        start_price = last_30min_data.iloc[0]['收盘']\n",
    "        end_price = last_30min_data.iloc[-1]['收盘']\n",
    "        return (end_price - start_price) / start_price * 100\n",
    "    except Exception as e:\n",
    "        print(f\"获取 {symbol} 分钟数据失败: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# 获取各指数收盘价及最后30分钟涨幅\n",
    "results = []\n",
    "for index_name, symbol in index_list.items():\n",
    "    # 获取日线数据（收盘价）\n",
    "    daily_data = ak.stock_zh_index_daily(symbol=symbol)\n",
    "    latest_close = daily_data['close'].iloc[-1]  # 最新收盘价\n",
    "    \n",
    "    # 获取最后30分钟涨幅\n",
    "    last_30min_change = get_index_last_30min_change(symbol)\n",
    "    \n",
    "    results.append({\n",
    "        \"指数名称\": index_name,\n",
    "        \"收盘价\": round(latest_close, 2),\n",
    "        \"最后30分钟涨幅 (%)\": round(last_30min_change, 2)\n",
    "    })\n",
    "\n",
    "# 转换为DataFrame输出\n",
    "result_df = pd.DataFrame(results)\n",
    "print(\"\\nA股主要指数收盘价及尾盘涨幅:\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "index_list = {\n",
    "    \"上证指数\": \"sh000001\",\n",
    "    \"沪深300\": \"sh000300\",\n",
    "    \"深证成指\": \"sz399001\",\n",
    "    \"创业板指\": \"sz399006\",\n",
    "    \"科创50\": \"sh000688\"\n",
    "}\n",
    "\n",
    "for index_name, index_code in index_list.items():\n",
    "    try:\n",
    "        # 获取30分钟数据，period设置为'30'\n",
    "        df = ak.stock_zh_index_minute(symbol=index_code, period='30')\n",
    "        print(f\"{index_name} ({index_code}) 的30分钟数据：\")\n",
    "        print(df.head())  # 打印前几行数据\n",
    "    except Exception as e:\n",
    "        print(f\"获取 {index_name} ({index_code}) 数据失败，错误信息：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "\n",
    "# 定义指数列表\n",
    "index_list = {\n",
    "    \"上证指数\": \"000001\",\n",
    "    \"沪深300\": \"000300\",\n",
    "    \"深证成指\": \"399001\",\n",
    "    \"创业板指\": \"399006\",\n",
    "    \"科创50\": \"000688\"\n",
    "}\n",
    "\n",
    "# 遍历指数列表，获取数据\n",
    "for index_name, index_code in index_list.items():\n",
    "    try:\n",
    "        # 使用 stock_zh_index_hist_min_em 方法获取指数数据\n",
    "        df = ak.index_zh_a_hist(\n",
    "            symbol=index_code, \n",
    "            period='30',  # 30分钟周期\n",
    "            start_date=\"2025-02-26 09:30:00\",  # 自定义开始日期\n",
    "            end_date=\"2025-02-26 15:00:00\"     # 自定义结束日期\n",
    "        )\n",
    "        print(f\"{index_name} ({index_code}) 的30分钟数据：\")\n",
    "        print(df)\n",
    "    except Exception as e:\n",
    "        print(f\"获取 {index_name} ({index_code}) 数据失败，错误信息：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入原始概念板块列表\n",
    "from boards import concept_names\n",
    "\n",
    "# 将概念板块分类\n",
    "concept_categories = {\n",
    "    \"科技与数字化\": {\n",
    "        \"AI与计算\": [\n",
    "            \"人工智能\", \"云计算\", \"大数据\", \"算力概念\", \"边缘计算\", \"数字经济\", \"数字孪生\", \"东数西算\",\n",
    "            \"ChatGPT概念\", \"AIGC概念\", \"AI芯片\", \"AI智能体\", \"AI语料\", \"AI制药\", \"AI手机\", \"AI眼镜\",\n",
    "            \"智谱AI\", \"Kimi概念\", \"DeepSeek概念\", \"Sora概念\", \"多模态AI\", \"MLOps概念\", \"空间计算\",\n",
    "            \"时空大数据\", \"商汤概念\", \"人脑工程\", \"AIPC\", \"机器视觉\", \"国资云概念\",\n",
    "        ],\n",
    "        \n",
    "        \"芯片与半导体\": [\n",
    "            \"半导体概念\", \"国产芯片\", \"存储芯片\", \"汽车芯片\", \"第三代半导体\", \"第四代半导体\", \n",
    "            \"IGBT概念\", \"碳化硅\", \"氮化镓\", \"中芯概念\", \"华为海思\", \"英伟达概念\", \"EDA概念\", \"Chiplet概念\",\n",
    "            \"高带宽内存\",\n",
    "        ],\n",
    "        \n",
    "        \"通信与网络\": [\n",
    "            \"5G概念\", \"6G概念\", \"光通信模块\", \"F5G概念\", \"WiFi\", \"VPN\", \"天基互联\", \"量子通信\",\n",
    "            \"毫米波概念\", \"UWB概念\", \"RCS概念\", \"eSIM\", \"物联网\", \"IPv6\", \"铜缆高速连接\", \n",
    "            \"星闪概念\",\n",
    "        ],\n",
    "        \n",
    "        \"数字应用\": [\n",
    "            \"区块链\", \"数字货币\", \"元宇宙概念\", \"NFT概念\", \"Web3.0\", \"虚拟数字人\", \"虚拟现实\", \"增强现实\",\n",
    "            \"混合现实\", \"数据安全\", \"网络安全\", \"数据确权\", \"数据要素\", \"数字水印\", \"数字哨兵\", \"全息技术\",\n",
    "            \"知识产权\", \"数据中心\", \"EDR概念\", \"超清视频\"\n",
    "        ],\n",
    "\n",
    "        \"硬件设备\": [\n",
    "            \"LED\", \"OLED\", \"MiniLED\", \"MicroLED\", \"光刻机(胶)\", \"柔性屏(折叠屏)\", \n",
    "            \"玻璃基板\", \"PCB\", \"MLCC\", \"被动元件\", \"传感器\", \"激光雷达\", \"无线耳机\",\n",
    "            \"智能穿戴\", \"电子车牌\", \"3D摄像头\", \"屏下摄像\", \"裸眼3D\", \"3D玻璃\",\n",
    "            \"电子纸概念\", \"无线充电\", \"液冷概念\", \"SPD概念\", \n",
    "        ],\n",
    "        \n",
    "        \"互联网平台\": [\n",
    "            \"华为概念\", \"华为欧拉\", \"华为昇腾\", \"鸿蒙概念\", \"阿里概念\", \"百度概念\", \n",
    "            \"腾讯云\", \"抖音概念(字节概念)\", \"快手概念\", \"拼多多概念\", \"小红书概念\",\n",
    "            \"小米概念\", \"苹果概念\", \"富士康\", \"荣耀概念\",\n",
    "        ],\n",
    "        \n",
    "        \"企业信息化\": [\n",
    "            \"ERP概念\", \"智能家居\", \"智能电视\", \"智慧城市\", \"智慧政务\", \"智慧灯杆\",\n",
    "            \"智能机器\", \"财税数字化\", \"DRG/DIP\", \"PLC概念\", \"信创\", \"国产软件\",\n",
    "            \"电子身份证\",\n",
    "        ],\n",
    "\n",
    "        \"数字娱乐\": [\n",
    "            \"网络游戏\", \"电子竞技\", \"云游戏\", \"短剧互动游戏\", \"手游概念\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"新能源与环保\": {\n",
    "        \"清洁能源\": [\n",
    "            \"新能源\", \"风能\", \"太阳能\", \"氢能源\", \"核能核电\", \"生物质能发电\", \n",
    "            \"地热能\", \"绿色电力\", \"可控核聚变\",\n",
    "        ],\n",
    "        \n",
    "        \"能源设备\": [\n",
    "            \"光伏设备\", \"光伏建筑一体化\", \"光伏高速公路\", \"特高压\", \"TOPCon电池\",\n",
    "            \"超导概念\", \"虚拟电厂\", \"空气能热泵\", \"超超临界发电\", \"智能电网\"\n",
    "        ],\n",
    "        \n",
    "        \"储能技术\": [\n",
    "            \"储能\", \"熔盐储能\", \"抽水蓄能\", \"锂电池\", \"钠离子电池\", \"固态电池\", \n",
    "            \"钒电池\", \"燃料电池\", \"超级电容\", \"钙钛矿电池\", \"BC电池\",\n",
    "        ],\n",
    "\n",
    "        \"新能源汽车\": [\n",
    "            \"新能源车\", \"动力电池回收\", \"麒麟电池\", \"刀片电池\", \"HIT电池\",\n",
    "        ],\n",
    "        \n",
    "        \"节能减排\": [\n",
    "            \"节能环保\", \"碳交易\", \"碳基材料\", \"低碳冶金\", \"尾气治理\",\n",
    "        ],\n",
    "        \n",
    "        \"环境保护\": [\n",
    "            \"垃圾分类\", \"土壤修复\", \"海绵城市\", \"核污染防治\", \"降解塑料\",\n",
    "        ],\n",
    "    },\n",
    "    \n",
    "    \"医药与健康\": {\n",
    "        \"医疗器械\": [\n",
    "            \"医疗器械概念\", \"体外诊断\", \"血氧仪\", \"注射器概念\", \"抗菌面料\"\n",
    "        ],\n",
    "        \n",
    "        \"医疗服务\": [\n",
    "            \"医疗服务\", \"医疗美容\", \"互联医疗\", \"CRO\", \"医废处理\",\n",
    "            \"养老概念\", \"辅助生殖\", \"毛发医疗\",\n",
    "        ],\n",
    "        \n",
    "        \"创新医药\": [\n",
    "            \"创新药\", \"精准医疗\", \"基因测序\", \"单抗概念\", \"CAR-T细胞疗法\",\n",
    "            \"免疫治疗\", \"生物识别\", \"合成生物\", \"重组蛋白\", \"纳米银\",\n",
    "        ],\n",
    "        \n",
    "        \"传统医药\": [\n",
    "            \"中药概念\", \"化学制药\", \"生物疫苗\", \"生物制品\",\n",
    "            \"熊去氧胆酸\", \"地塞米松\", \"蒙脱石散\", \"青蒿素\", \n",
    "            \"千金藤素\", \"维生素\", \"肝素概念\", \"独家药品\"\n",
    "        ],\n",
    "\n",
    "        \"公共卫生\": [\n",
    "            \"健康中国\", \"新冠药物\", \"疫苗冷链\", \"口罩\", \"消毒剂\",\n",
    "            \"病毒防治\", \"流感\", \"气溶胶检测\", \"痘病毒防治\",\n",
    "            \"超级真菌\", \"幽门螺杆菌概念\", \"阿兹海默\", \"肝炎概念\",\n",
    "        ],\n",
    "        \n",
    "        \"健康管理\": [\n",
    "            \"减肥药\", \"长寿药\",\n",
    "        ],\n",
    "    },\n",
    "    \n",
    "    \"消费与服务\": {\n",
    "        \"食品饮料\": [\n",
    "            \"白酒\", \"啤酒概念\", \"调味品概念\", \"食品安全\", \"乳业\", \"预制菜概念\", \n",
    "            \"代糖概念\", \"娃哈哈概念\",\n",
    "        ],\n",
    "        \n",
    "        \"生活消费\": [\n",
    "            \"化妆品概念\", \"美容护理\", \"宠物经济\", \"婴童概念\", \"托育服务\", \n",
    "            \"电子烟\", \"超级品牌\", \"谷子经济\",\n",
    "        ],\n",
    "        \n",
    "        \"零售渠道\": [\n",
    "            \"新零售\", \"电商概念\", \"跨境电商\", \"社区团购\", \"免税概念\", \n",
    "            \"抖音小店\", \"快递概念\", \"冷链物流\", \"进口博览\", \"万达概念\", \"内贸流通\",\n",
    "            \"地摊经济\",\n",
    "        ],\n",
    "        \n",
    "        \"服务业态\": [\n",
    "            \"在线旅游\", \"在线教育\", \"网红直播\", \"盲盒经济\", \"职业教育\",\n",
    "            \"共享经济\", \"远程办公\", \"彩票概念\", \"赛马概念\",\n",
    "        ],\n",
    "        \n",
    "        \"商业模式\": [\n",
    "            \"C2M概念\", \"新型工业化\", \"数字阅读\",\n",
    "        ],\n",
    "\n",
    "        \"文化体育\": [\n",
    "            \"体育产业\", \"世界杯\", \"中超概念\", \"冰雪经济\", \"户外露营\", \"影视概念\",\n",
    "        ],\n",
    "    },\n",
    "    \n",
    "    \"制造与工业\": {\n",
    "        \"先进制造\": [\n",
    "            \"工业4.0\", \"工业互联\", \"智能制造\", \"专精特新\", \"工业母机\", \n",
    "            \"3D打印\", \"新型工业化\",\n",
    "        ],\n",
    "        \n",
    "        \"机器人\": [\n",
    "            \"机器人概念\", \"人形机器人\", \"机器人执行器\", \"减速器\", \"同步磁阻电机\",\n",
    "        ],\n",
    "        \n",
    "        \"汽车工业\": [\n",
    "            \"汽车整车\", \"汽车零部件\", \"汽车服务\", \"特斯拉\", \"华为汽车\", \"小米汽车\", \n",
    "            \"汽车热管理\", \"汽车一体化压铸\", \"无人驾驶\", \"车联网(车路云)\", \n",
    "            \"电子后视镜\", \"胎压监测\", \"轮毂电机\", \"充电桩\", \"换电概念\", \n",
    "            \"高压快充\", \"飞行汽车(eVTOL)\", \"汽车拆解\",\n",
    "        ],\n",
    "        \n",
    "        \"工业材料\": [\n",
    "            \"新材料\", \"稀土永磁\", \"石墨烯\", \"碳纤维\", \"稀缺资源\", \"工业大麻\",\n",
    "            \"小金属概念\", \"锂矿概念\", \"有机硅\", \"PEEK材料概念\", \"培育钻石\", \"民爆概念\",\n",
    "        ],\n",
    "\n",
    "        \"工业设备\": [\n",
    "            \"工程机械概念\", \"工业气体\", \"氦气概念\", \"装配建筑\", \"通用航空\"\n",
    "            \"磁悬浮概念\", \"海工装备\", \"无人机\", \"复合集流体\", \"植物照明\",\n",
    "        ],\n",
    "        \n",
    "        \"建筑工业\": [\n",
    "            \"建筑节能\", \"铁路基建\", \"装配建筑\", \n",
    "        ],\n",
    "    },\n",
    "    \n",
    "    \"金融与投资\": {\n",
    "        \"金融服务\": [\n",
    "            \"银行\", \"证券\", \"保险\", \"多元金融\", \"互联金融\", \"券商概念\", \"移动支付\",\n",
    "            \"京东金融\", \"蚂蚁概念\", \"参股银行\", \"参股券商\", \"跨境支付\", \"ETC\",\n",
    "            \"参股保险\", \"参股期货\",\n",
    "        ],\n",
    "        \n",
    "        \"投资主题\": [\n",
    "            \"融资融券\", \"创投\", \"REITs概念\", \"独角兽\", \"股权激励\", \"并购重组概念\",\n",
    "            \"股权转让\", \"举牌\", \"基金重仓\", \"社保重仓\", \"机构重仓\", \"高送转\",\n",
    "            \"QFII重仓\", \"证金持股\", \"转债标的\", \"贬值受益\",\n",
    "        ],\n",
    "\n",
    "        \"指数成分\": [\n",
    "            \"沪股通\", \"深股通\", \"富时罗素\", \"MSCI中国\", \"标准普尔\",\n",
    "        ],\n",
    "\n",
    "        \"交易市场\": [\n",
    "            \"B股\", \"AB股\", \"AH股\", \"GDR\", \"北交所概念\", \n",
    "            \"科创板做市商\", \"科创板做市股\", \"参股新三板\", \"IPO受益\",\n",
    "        ],\n",
    "        \n",
    "        \"金融创新\": [\n",
    "            \"纾困概念\", \"养老金\", \"租售同权\", \"首发经济\", \"化债(AMC)概念\",\n",
    "        ],\n",
    "    },\n",
    "    \n",
    "    \"国家战略与区域发展\": {\n",
    "        \"区域发展战略\": [\n",
    "            \"一带一路\", \"京津冀\", \"雄安新区\", \"长江三角\", \"粤港自贸\", \"东北振兴\", \"西部大开发\",\n",
    "            \"成渝特区\", \"深圳特区\", \"上海自贸\", \"湖北自贸\", \"滨海新区\", \"乡村振兴\", \"新型城镇化\",\n",
    "            \"土地流转\", \"沪企改革\",\n",
    "        ],\n",
    "        \n",
    "        \"国企与军工\": [\n",
    "            \"国企改革\", \"央企改革\", \"中字头\", \"军工\", \"航天航空\", \"航母概念\", \"大飞机\", \"军民融合\",\n",
    "            \"国家安防\", \"商业航天\", \"北斗导航\", \"空间站概念\",\n",
    "        ],\n",
    "\n",
    "        \"国际合作\": [\n",
    "            \"东盟自贸区概念\", \"RCEP概念\", \"中特估\", \"中俄贸易概念\",\n",
    "        ],\n",
    "        \n",
    "        \"发展规划\": [\n",
    "            \"2025规划\", \"统一大市场\", \"供销社概念\", \"PPP模式\",\n",
    "        ],\n",
    "    },\n",
    "    \n",
    "    \"资源与能源\": {\n",
    "        \"传统能源\": [\n",
    "            \"石油行业\", \"天然气\", \"煤炭行业\", \"煤化工\", \"页岩气\", \"油气设服\", \"可燃冰\",\n",
    "            \"发电机概念\",\n",
    "        ],\n",
    "        \n",
    "        \"农业资源\": [\n",
    "            \"农业种植\", \"农牧饲渔\", \"水产养殖\", \"粮食概念\", \"生态农业\", \"转基因\", \"草甘膦\",\n",
    "            \"猪肉概念\", \"鸡肉概念\", \"人造肉\",\n",
    "        ],\n",
    "        \n",
    "        \"矿产资源\": [\n",
    "            \"有色金属\", \"贵金属\", \"黄金概念\", \"钛白粉\", \"磷化工\", \"氟化工\",\n",
    "        ],\n",
    "\n",
    "        \"化工材料\": [\n",
    "            \"化工原料\", \"环氧丙烷\", \"PVDF概念\", \"蓝宝石\",\n",
    "        ],\n",
    "        \n",
    "        \"水资源\": [\n",
    "            \"水利建设\", \"净水概念\", \"海洋经济\",\n",
    "        ],\n",
    "    },\n",
    "    \n",
    "\n",
    "    \"基建与公共服务\": {\n",
    "        \"基础设施\": [\n",
    "            \"地下管网\", \"低空经济\", \"广电\",\n",
    "        ],\n",
    "        \n",
    "        \"公共服务\": [\n",
    "            \"噪声防治\", \"房屋检测\", \"退税商店\", \"CPO概念\",\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    \"其他特色主题\": {\n",
    "        \"特色指数\": [\n",
    "            \"上证50_\", \"上证180_\", \"上证380\", \"中证500\", \"HS300_\", \"深证100R\", \"深成500\",\n",
    "            \"创业成份\", \"创业板综\", \"央视50_\", \"茅指数\", \"宁组合\",\n",
    "        ],\n",
    "        \n",
    "        \"特殊状态\": [\n",
    "            \"ST股\", \"次新股\", \"注册制次新股\", \"低价股\", \"百元股\", \"微盘股\", \"破净股\",\n",
    "            \"昨日涨停\", \"昨日涨停_含一字\", \"昨日连板\", \"昨日连板_含一字\", \"昨日触板\",\n",
    "            \"预盈预增\", \"预亏预减\", \"壳资源\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "# 创建反向映射，用于检查分类情况\n",
    "all_categorized = []\n",
    "category_mapping = {}  # 记录每个概念属于哪个大类和子类\n",
    "duplicates = []  # 记录重复分类的概念\n",
    "\n",
    "# 遍历所有分类\n",
    "for category, subcategories in concept_categories.items():\n",
    "    if isinstance(subcategories, dict):\n",
    "        # 处理有子类的大类\n",
    "        for subcategory, concepts in subcategories.items():\n",
    "            for concept in concepts:\n",
    "                all_categorized.append(concept)\n",
    "                # 检查是否重复分类\n",
    "                if concept in category_mapping:\n",
    "                    duplicates.append({\n",
    "                        \"concept\": concept,\n",
    "                        \"original\": category_mapping[concept],\n",
    "                        \"duplicate\": {\"category\": category, \"subcategory\": subcategory}\n",
    "                    })\n",
    "                else:\n",
    "                    category_mapping[concept] = {\n",
    "                        \"category\": category,\n",
    "                        \"subcategory\": subcategory\n",
    "                    }\n",
    "    else:\n",
    "        # 处理没有子类的大类\n",
    "        for concept in subcategories:\n",
    "            all_categorized.append(concept)\n",
    "            if concept in category_mapping:\n",
    "                duplicates.append({\n",
    "                    \"concept\": concept,\n",
    "                    \"original\": category_mapping[concept],\n",
    "                    \"duplicate\": {\"category\": category, \"subcategory\": None}\n",
    "                })\n",
    "            else:\n",
    "                category_mapping[concept] = {\n",
    "                    \"category\": category,\n",
    "                    \"subcategory\": None\n",
    "                }\n",
    "\n",
    "# 检查未分类的概念\n",
    "uncategorized = [concept for concept in concept_names if concept not in all_categorized]\n",
    "\n",
    "# 打印分类结果\n",
    "if __name__ == \"__main__\":\n",
    "    # 打印分类统计\n",
    "    print(\"\\n=== 分类统计 ===\")\n",
    "    category_stats = {}\n",
    "    for mapping in category_mapping.values():\n",
    "        cat = mapping[\"category\"]\n",
    "        subcat = mapping[\"subcategory\"]\n",
    "        if cat not in category_stats:\n",
    "            category_stats[cat] = {\"total\": 0, \"subcategories\": {}}\n",
    "        category_stats[cat][\"total\"] += 1\n",
    "        if subcat:\n",
    "            if subcat not in category_stats[cat][\"subcategories\"]:\n",
    "                category_stats[cat][\"subcategories\"][subcat] = 0\n",
    "            category_stats[cat][\"subcategories\"][subcat] += 1\n",
    "\n",
    "    for cat, stats in category_stats.items():\n",
    "        print(f\"\\n{cat}（共{stats['total']}个概念）:\")\n",
    "        if stats[\"subcategories\"]:\n",
    "            for subcat, count in stats[\"subcategories\"].items():\n",
    "                print(f\"  - {subcat}：{count}个\")\n",
    "\n",
    "    # 打印重复分类\n",
    "    if duplicates:\n",
    "        print(\"\\n=== 重复分类 ===\")\n",
    "        for dup in duplicates:\n",
    "            print(f\"\\n概念「{dup['concept']}」出现在多个分类中：\")\n",
    "            print(f\"  - 原始分类：{dup['original']['category']}\", end=\"\")\n",
    "            if dup['original']['subcategory']:\n",
    "                print(f\" / {dup['original']['subcategory']}\")\n",
    "            print(f\"  - 重复分类：{dup['duplicate']['category']}\", end=\"\")\n",
    "            if dup['duplicate']['subcategory']:\n",
    "                print(f\" / {dup['duplicate']['subcategory']}\")\n",
    "\n",
    "    # 打印未分类概念\n",
    "    if uncategorized:\n",
    "        print(f\"\\n=== 未分类概念（{len(uncategorized)}个）===\")\n",
    "        print(\", \".join(uncategorized))\n",
    "\n",
    "    # 打印总体统计\n",
    "    print(f\"\\n=== 总体统计 ===\")\n",
    "    print(f\"大类数量：{len(category_stats)}个\")\n",
    "    print(f\"已分类概念：{len(category_mapping)}个\")\n",
    "    print(f\"重复分类概念：{len(duplicates)}个\")\n",
    "    print(f\"未分类概念：{len(uncategorized)}个\")\n",
    "    print(f\"原始概念总数：{len(concept_names)}个\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adata\n",
    "df = adata.stock.market.all_capital_flow_east(days_type=5)\n",
    "filtered_df = df[df[\"index_code\"] == \"BK0800\"]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adata\n",
    "\n",
    "res_dq = adata.stock.info.all_concept_code_east()\n",
    "print(res_dq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dc = adata.stock.market.get_market_concept_east(\"BK1173\")\n",
    "\n",
    "print(res_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adata\n",
    "\n",
    "# 设置代理,代理是全局设置,代理失效后可重新设置。参数:ip,proxy_url\n",
    "adata.proxy(is_proxy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to capital_flow.json with 145 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import adata\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Get the capital flow data\n",
    "df = adata.stock.market.all_capital_flow_east(days_type=5)\n",
    "\n",
    "# Save to JSON file with proper encoding for Chinese characters using pandas\n",
    "\n",
    "print(f\"Data saved to capital_flow.json with {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#選股\n",
    "\n",
    "#實時板塊數據\n",
    "import adata\n",
    "df = adata.stock.market.get_market_concept_current_east(index_code='BK0612')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adata\n",
    "df = adata.stock.market.get_capital_flow(stock_code='000001')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'index_code': 'BK1015', 'index_name': '能源金属', 'capital_flow': {'strength_ratio': 1108.7, 'trend_type': '短期过热', 'daily_sequence': [{'days': 10, 'net_inflow': 839000816.0, 'change_pct': 6.33}, {'days': 5, 'net_inflow': 1550043536.0, 'change_pct': 5.96}, {'days': 1, 'net_inflow': 930234736.0, 'change_pct': 3.6}]}, 'risk_indicators': {'small_capital_outflow': True, 'mid_capital_behavior': '撤离', 'large_capital_analysis': {'lg_strength_ratio': 1229.1, 'lg_acceleration': True, 'lg_price_divergence': False}}}]\n"
     ]
    }
   ],
   "source": [
    "def filter_high_potential_sectors(data):\n",
    "    \"\"\"\n",
    "    基于多周期资金流数据的板块筛选函数\n",
    "    新增功能：大额资金流三重维度风险分析\n",
    "    \"\"\"\n",
    "    qualified_sectors = []\n",
    "    \n",
    "    for sector in data:\n",
    "        # 获取周期数据；如果缺失，则跳过该板块\n",
    "        d1 = sector.get('days_type_1')\n",
    "        d5 = sector.get('days_type_5')\n",
    "        d10 = sector.get('days_type_10')\n",
    "        if not (d1 and d5 and d10):\n",
    "            continue\n",
    "\n",
    "        # 检查必备的字段是否存在，若缺失则跳过\n",
    "        main_net_inflow_d10 = d10.get('main_net_inflow')\n",
    "        main_net_inflow_d5 = d5.get('main_net_inflow')\n",
    "        flow_1 = d1.get('main_net_inflow')\n",
    "        if main_net_inflow_d10 is None or main_net_inflow_d5 is None or flow_1 is None:\n",
    "            continue\n",
    "\n",
    "        # 计算关键指标\n",
    "        daily_10 = main_net_inflow_d10 / 10 if main_net_inflow_d10 else 0\n",
    "        daily_5 = main_net_inflow_d5 / 5 if main_net_inflow_d5 else 0\n",
    "        \n",
    "        # 大额资金分析预处理（检查数据是否存在）\n",
    "        lg_net_inflow_d10 = d10.get('lg_net_inflow')\n",
    "        lg_net_inflow_d5 = d5.get('lg_net_inflow')\n",
    "        lg_flow_1 = d1.get('lg_net_inflow')\n",
    "        if lg_net_inflow_d10 is None or lg_net_inflow_d5 is None or lg_flow_1 is None:\n",
    "            continue\n",
    "        lg_daily_10 = lg_net_inflow_d10 / 10 if lg_net_inflow_d10 else 0\n",
    "        lg_daily_5 = lg_net_inflow_d5 / 5 if lg_net_inflow_d5 else 0\n",
    "\n",
    "        # 核心条件判断\n",
    "        condition_continuity = (daily_10 <= daily_5 * 1.1) and (daily_5 <= flow_1 * 1.1)\n",
    "        # 避免除零错误，若daily_10为0，则用1e-6代替\n",
    "        strength_ratio = (flow_1 / (daily_10 + 1e-6)) * 100  \n",
    "        condition_strength = strength_ratio > 150\n",
    "\n",
    "        # 获取涨跌幅数据\n",
    "        d1_change_pct = d1.get('change_pct')\n",
    "        d5_change_pct = d5.get('change_pct')\n",
    "        d10_change_pct = d10.get('change_pct')\n",
    "        if d1_change_pct is None or d5_change_pct is None or d10_change_pct is None:\n",
    "            continue\n",
    "\n",
    "        # 量价健康度验证（注意：这里调整了顺序以匹配示例数据）\n",
    "        price_condition = (d1_change_pct > 0 and d10_change_pct > d5_change_pct and d1_change_pct < 7)\n",
    "\n",
    "        # 新增大额资金风险指标\n",
    "        lg_strength_ratio = round((lg_flow_1 / (lg_daily_10 + 1e-6) * 100), 1)\n",
    "        lg_acceleration = lg_daily_5 > lg_daily_10\n",
    "        lg_price_divergence = (lg_flow_1 > 0) and (d1_change_pct < 1)\n",
    "        lg_risk_indicators = {\n",
    "            \"lg_strength_ratio\": lg_strength_ratio,\n",
    "            \"lg_acceleration\": lg_acceleration,\n",
    "            \"lg_price_divergence\": lg_price_divergence\n",
    "        }\n",
    "\n",
    "        # 主力资金验证（检查必要的流入率字段）\n",
    "        d1_main_net_inflow_rate = d1.get('main_net_inflow_rate')\n",
    "        d5_main_net_inflow_rate = d5.get('main_net_inflow_rate')\n",
    "        d10_main_net_inflow_rate = d10.get('main_net_inflow_rate')\n",
    "        if d1_main_net_inflow_rate is None or d5_main_net_inflow_rate is None or d10_main_net_inflow_rate is None:\n",
    "            continue\n",
    "        capital_condition = (d1_main_net_inflow_rate > 0.8 and\n",
    "                             d5_main_net_inflow_rate > 0.3 and \n",
    "                             d10_main_net_inflow_rate > -0.1)\n",
    "        \n",
    "        if all([condition_continuity, condition_strength, price_condition, capital_condition]):\n",
    "            sector_data = {\n",
    "                \"index_code\": sector.get('index_code'),\n",
    "                \"index_name\": sector.get('index_name'),\n",
    "                \"capital_flow\": {\n",
    "                    \"strength_ratio\": round(strength_ratio, 1),\n",
    "                    \"trend_type\": \"阶梯式流入\" if strength_ratio < 300 else \"短期过热\",\n",
    "                    \"daily_sequence\": [\n",
    "                        {\"days\": 10, \"net_inflow\": d10.get('main_net_inflow'), \"change_pct\": d10.get('change_pct')},\n",
    "                        {\"days\": 5, \"net_inflow\": d5.get('main_net_inflow'), \"change_pct\": d5.get('change_pct')},\n",
    "                        {\"days\": 1, \"net_inflow\": d1.get('main_net_inflow'), \"change_pct\": d1.get('change_pct')}\n",
    "                    ]\n",
    "                },\n",
    "                \"risk_indicators\": {\n",
    "                    \"small_capital_outflow\": d1.get('sm_net_inflow', 0) < 0,\n",
    "                    \"mid_capital_behavior\": \"跟风\" if d1.get('mid_net_inflow_rate', 0) > 0 else \"撤离\",\n",
    "                    \"large_capital_analysis\": lg_risk_indicators\n",
    "                }\n",
    "            }\n",
    "            qualified_sectors.append(sector_data)\n",
    "    \n",
    "    return qualified_sectors\n",
    "\n",
    "\n",
    "# 假设您的原始数据格式如下\n",
    "sample_data = [\n",
    "    {\n",
    "        \"index_code\": \"BK1015\",\n",
    "        \"index_name\": \"能源金属\",\n",
    "        \"days_type_1\": {\n",
    "            \"change_pct\": 3.6,\n",
    "            \"main_net_inflow\": 930234736.0,\n",
    "            \"main_net_inflow_rate\": 5.61,\n",
    "            \"max_net_inflow\": 529605232.0,\n",
    "            \"max_net_inflow_rate\": 3.19,\n",
    "            \"lg_net_inflow\": 400629504.0,\n",
    "            \"lg_net_inflow_rate\": 2.42,\n",
    "            \"mid_net_inflow\": -245510912.0,\n",
    "            \"mid_net_inflow_rate\": -1.48,\n",
    "            \"sm_net_inflow\": -684723760.0,\n",
    "            \"sm_net_inflow_rate\": -4.13,\n",
    "            \"stock_code\": \"华友钴业\",\n",
    "            \"stock_name\": \"603799\"\n",
    "        },\n",
    "        \"days_type_5\": {\n",
    "            \"change_pct\": 5.96,\n",
    "            \"main_net_inflow\": 1550043536.0,\n",
    "            \"main_net_inflow_rate\": 2.59,\n",
    "            \"max_net_inflow\": 967757040.0,\n",
    "            \"max_net_inflow_rate\": 1.62,\n",
    "            \"lg_net_inflow\": 582286496.0,\n",
    "            \"lg_net_inflow_rate\": 0.97,\n",
    "            \"mid_net_inflow\": -31947936.0,\n",
    "            \"mid_net_inflow_rate\": -0.05,\n",
    "            \"sm_net_inflow\": -1518095536.0,\n",
    "            \"sm_net_inflow_rate\": -2.54,\n",
    "            \"stock_code\": \"华友钴业\",\n",
    "            \"stock_name\": \"603799\"\n",
    "        },\n",
    "        \"days_type_10\": {\n",
    "            \"change_pct\": 6.33,\n",
    "            \"main_net_inflow\": 839000816.0,\n",
    "            \"main_net_inflow_rate\": 0.93,\n",
    "            \"max_net_inflow\": 513060016.0,\n",
    "            \"max_net_inflow_rate\": 0.57,\n",
    "            \"lg_net_inflow\": 325940800.0,\n",
    "            \"lg_net_inflow_rate\": 0.36,\n",
    "            \"mid_net_inflow\": 40740320.0,\n",
    "            \"mid_net_inflow_rate\": 0.05,\n",
    "            \"sm_net_inflow\": -879741072.0,\n",
    "            \"sm_net_inflow_rate\": -0.97,\n",
    "            \"stock_code\": \"华友钴业\",\n",
    "            \"stock_name\": \"603799\"\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "# 执行筛选\n",
    "result = filter_high_potential_sectors(sample_data)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 示例：分析某只股票\u001b[39;00m\n\u001b[0;32m     43\u001b[0m stock_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000001\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 44\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_stock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2025-03-04\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2025-02-18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m analysis_results \u001b[38;5;241m=\u001b[39m analyze_stock_fund_flow(df)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(analysis_results)\n",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m, in \u001b[0;36mget_stock_data\u001b[1;34m(stock_code, start_date, end_date)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stock_data\u001b[39m(stock_code, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_capital_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstock_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\adata\\stock\\market\\capital_flow\\stock_capital_flow.py:43\u001b[0m, in \u001b[0;36mStockCapitalFlow.get_capital_flow\u001b[1;34m(self, stock_code, start_date, end_date)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_capital_flow\u001b[39m(\u001b[38;5;28mself\u001b[39m, stock_code: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000001\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    获取单个股票的资金流向-日度\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    只能获取最近2年多的数据\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    :return: 资金流向-日度\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaidu_capital_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_capital_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\adata\\stock\\market\\capital_flow\\stock_capital_flow_baidu.py:78\u001b[0m, in \u001b[0;36mStockCapitalFlowBaidu.get_capital_flow\u001b[1;34m(self, stock_code, start_date, end_date)\u001b[0m\n\u001b[0;32m     74\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://finance.pae.baidu.com/vapi/v1/fundsortlist?\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m     75\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&market=ab&finance_type=stock&tab=day&\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m     76\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom=history&date=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&pn=0&rn=20&finClientType=pc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m'\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39mbaidu_headers\u001b[38;5;241m.\u001b[39mjson_headers, proxies\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m---> 78\u001b[0m data_list \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import adata\n",
    "import pandas as pd\n",
    "\n",
    "# 获取股票资金流向数据\n",
    "def get_stock_data(stock_code, start_date=None, end_date=None):\n",
    "    df = adata.stock.market.get_capital_flow(stock_code=stock_code, start_date=start_date, end_date=end_date)\n",
    "    return df\n",
    "\n",
    "# 识别资金流向形态\n",
    "def analyze_stock_fund_flow(df):\n",
    "    df = df.sort_values(by='trade_date', ascending=True)  # 按日期升序排列\n",
    "    df['net_flow_10d'] = df['lg_net_inflow'].rolling(window=10).sum()  # 10日资金净流入\n",
    "    df['net_flow_5d'] = df['lg_net_inflow'].rolling(window=5).sum()  # 5日资金净流入\n",
    "    df['net_flow_1d'] = df['lg_net_inflow']  # 1日资金净流入\n",
    "\n",
    "    analysis_results = []\n",
    "\n",
    "    for i in range(10, len(df)):  # 确保至少有10天的数据\n",
    "        row = df.iloc[i]\n",
    "        prev_row = df.iloc[i-1]\n",
    "\n",
    "        # 形态1：阶梯式资金流入\n",
    "        if (row['net_flow_10d'] > df.iloc[i-1]['net_flow_10d'] and\n",
    "            row['net_flow_5d'] > df.iloc[i-1]['net_flow_5d'] and\n",
    "            row['net_flow_1d'] > df.iloc[i-1]['net_flow_1d']):\n",
    "            analysis_results.append((row['trade_date'], row['stock_code'], '阶梯式资金流入'))\n",
    "\n",
    "        # 形态2：短期过热\n",
    "        if (row['net_flow_1d'] > 3 * row['net_flow_5d'] / 5 and \n",
    "            row['net_flow_5d'] < df.iloc[i-1]['net_flow_5d']):\n",
    "            analysis_results.append((row['trade_date'], row['stock_code'], '短期过热'))\n",
    "\n",
    "        # 形态3：长期筑底反转\n",
    "        if (row['net_flow_10d'] > df.iloc[i-1]['net_flow_10d'] and\n",
    "            row['net_flow_5d'] > df.iloc[i-1]['net_flow_5d'] and\n",
    "            row['net_flow_1d'] > 0 and\n",
    "            prev_row['net_flow_1d'] < 0):  # 前一天资金流入为负，今日放量长阳\n",
    "            analysis_results.append((row['trade_date'], row['stock_code'], '长期筑底反转'))\n",
    "\n",
    "    return pd.DataFrame(analysis_results, columns=['trade_date', 'stock_code', 'pattern'])\n",
    "\n",
    "# 示例：分析某只股票\n",
    "stock_code = '000001'\n",
    "df = get_stock_data(stock_code, \"2025-03-04\", \"2025-02-18\")\n",
    "analysis_results = analyze_stock_fund_flow(df)\n",
    "\n",
    "print(analysis_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "构建概念映射: 100%|██████████| 5427/5427 [39:00<00:00,  2.32股/s, 当前股票=689009, 概念数=6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "样例股票 600020 的概念代码：\n",
      "['BK0980', 'BK0700', 'BK0683', 'BK0604', 'BK0506']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m total_stocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mapping)\n\u001b[0;32m     58\u001b[0m stocks_with_concepts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m v)\n\u001b[1;32m---> 59\u001b[0m avg_concepts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m total_stocks \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtotal_stats\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m统计：共\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_stocks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m只股票，\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstocks_with_concepts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m只含概念，平均每只股票\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_concepts\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m个概念\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_stats' is not defined"
     ]
    }
   ],
   "source": [
    "import adata\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_stock_concept_mapping():\n",
    "    \"\"\"\n",
    "    创建股票-概念代码映射字典\n",
    "    \n",
    "    返回结构示例：\n",
    "    {\n",
    "        \"600020\": [\"BK0685\", \"BK0700\", \"BK0683\", ...],\n",
    "        \"000001\": [\"BK0521\", \"BK0732\", ...],\n",
    "        # 其他股票...\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 获取全量股票并过滤北交所\n",
    "        all_stock = adata.stock.info.all_code()\n",
    "        filtered_stock = all_stock[all_stock['exchange'] != 'BJ']\n",
    "        stock_codes = filtered_stock['stock_code'].unique().tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"获取股票列表失败：{str(e)}\")\n",
    "        return {}\n",
    "\n",
    "    concept_map = {}\n",
    "    \n",
    "    with tqdm(stock_codes, desc='构建概念映射', unit='股') as pbar:\n",
    "        for code in pbar:\n",
    "            try:\n",
    "                # 获取概念数据\n",
    "                df = adata.stock.info.get_concept_east(stock_code=code)\n",
    "                \n",
    "                # 提取唯一概念代码\n",
    "                if not df.empty:\n",
    "                    concepts = df['concept_code'].drop_duplicates().tolist()\n",
    "                else:\n",
    "                    concepts = []\n",
    "                \n",
    "                concept_map[code] = concepts\n",
    "                pbar.set_postfix({'当前股票': code, '概念数': len(concepts)})\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n股票 {code} 处理异常：{str(e)}\")\n",
    "                concept_map[code] = []\n",
    "    \n",
    "    return concept_map\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == '__main__':\n",
    "    mapping = create_stock_concept_mapping()\n",
    "    \n",
    "    # 验证样例输出\n",
    "    sample_code = '600020'\n",
    "    print(f\"\\n样例股票 {sample_code} 的概念代码：\")\n",
    "    print(mapping.get(sample_code, []))\n",
    "    \n",
    "    # 统计信息\n",
    "    total_stocks = len(mapping)\n",
    "    stocks_with_concepts = sum(1 for v in mapping.values() if v)\n",
    "\n",
    "    print(f\"\\n统计：共{total_stocks}只股票，{stocks_with_concepts}只含概念，平均每只股票{avg_concepts:.1f}个概念\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5427\n"
     ]
    }
   ],
   "source": [
    "total_stocks = len(mapping)\n",
    "print(total_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功！文件路径: stock_concept_map_20250305_155359.json\n",
      "文件大小: 585.59 KB\n",
      "\n",
      "文件验证结果:\n",
      "包含股票数量: 5427\n",
      "示例数据: [('000001', ['BK1071', 'BK0830', 'BK0637', 'BK0549']), ('000002', ['BK0992', 'BK0945', 'BK0822', 'BK0811', 'BK0882', 'BK0680', 'BK0653', 'BK0549'])]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def save_concept_map(concept_map, file_path=None):\n",
    "    \"\"\"\n",
    "    将股票-概念映射字典保存为JSON文件\n",
    "    \n",
    "    参数:\n",
    "    concept_map (dict): 通过create_stock_concept_mapping()生成的字典\n",
    "    file_path (str): 可选的文件保存路径，默认当前目录\n",
    "    \n",
    "    返回:\n",
    "    str: 最终保存的文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 生成带时间戳的文件名\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"stock_concept_map_{timestamp}.json\"\n",
    "        \n",
    "        # 处理保存路径\n",
    "        if file_path:\n",
    "            os.makedirs(file_path, exist_ok=True)\n",
    "            full_path = os.path.join(file_path, filename)\n",
    "        else:\n",
    "            full_path = filename\n",
    "        \n",
    "        # 写入文件\n",
    "        with open(full_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(concept_map, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # 验证文件大小\n",
    "        file_size = os.path.getsize(full_path) / 1024  # 转换为KB\n",
    "        print(f\"保存成功！文件路径: {full_path}\")\n",
    "        print(f\"文件大小: {file_size:.2f} KB\")\n",
    "        return full_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"保存失败: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == '__main__':\n",
    "    # 先创建映射字典\n",
    "    concept_mapping = {\n",
    "        \"600020\": [\"BK0685\", \"BK0700\", \"BK0683\", \"BK0604\", \"BK0506\"],\n",
    "        \"000001\": [\"BK0521\", \"BK0732\", \"BK0811\"],\n",
    "        \"000002\": [\"BK0423\", \"BK0556\", \"BK0683\"]\n",
    "    }\n",
    "    \n",
    "    # 保存到当前目录\n",
    "    saved_file = save_concept_map(mapping)\n",
    "    \n",
    "    # 保存到指定目录\n",
    "    # save_concept_map(concept_mapping, file_path=\"data/stock_concepts\")\n",
    "    \n",
    "    # 验证文件内容\n",
    "    if saved_file and os.path.exists(saved_file):\n",
    "        with open(saved_file, 'r', encoding='utf-8') as f:\n",
    "            loaded_data = json.load(f)\n",
    "            print(\"\\n文件验证结果:\")\n",
    "            print(f\"包含股票数量: {len(loaded_data)}\")\n",
    "            print(f\"示例数据: {list(loaded_data.items())[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "def get_today_date():\n",
    "    \"\"\"\n",
    "    Returns today's date in 'YYYY-MM-DD' format using China Standard Time (CST).\n",
    "    \n",
    "    Returns:\n",
    "        str: Today's date string in 'YYYY-MM-DD' format\n",
    "    \"\"\"\n",
    "    # Get current time in China Standard Time\n",
    "    china_tz = pytz.timezone('Asia/Shanghai')\n",
    "    current_time_china = datetime.now(china_tz)\n",
    "    \n",
    "    # Format the date as YYYY-MM-DD\n",
    "    formatted_date = current_time_china.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return formatted_date\n",
    "\n",
    "# Convert DataFrame to the desired JSON structure\n",
    "def stock_capital_flow_df_to_json(dataframe):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to a specific JSON structure\n",
    "    \"\"\"\n",
    "    if dataframe.empty:\n",
    "        return {\"stock_code\": \"\", \"capital_flow\": []}\n",
    "    \n",
    "    # Get the stock code from the first row\n",
    "    stock_code = dataframe['stock_code'].iloc[0]\n",
    "    \n",
    "    # Convert each row to a dictionary and build the data list\n",
    "    data_list = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        data_item = {\n",
    "            \"trade_date\": row['trade_date'],\n",
    "            \"main_net_inflow\": float(row['main_net_inflow']),\n",
    "            \"sm_net_inflow\": float(row['sm_net_inflow']),\n",
    "            \"mid_net_inflow\": float(row['mid_net_inflow']),\n",
    "            \"lg_net_inflow\": float(row['lg_net_inflow']),\n",
    "            \"max_net_inflow\": float(row['max_net_inflow'])\n",
    "        }\n",
    "        data_list.append(data_item)\n",
    "    \n",
    "    # Create the final JSON structure\n",
    "    result = {\n",
    "        \"stock_code\": stock_code,\n",
    "        \"capital_flow\": data_list\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "获取资金流向: 100%|██████████| 5/5 [00:04<00:00,  1.16股/s, 000333: 成功获取9天数据]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最近资金流向数据概览：\n",
      "  stock_code  trade_date  main_net_inflow  max_net_inflow  lg_net_inflow  \\\n",
      "0     000001  2025-03-04       32952600.0      74209500.0    -41256900.0   \n",
      "1     000001  2025-03-03       -4594200.0       -516000.0     -4078200.0   \n",
      "2     000001  2025-02-28      -45980800.0     -27083700.0    -18897100.0   \n",
      "3     000001  2025-02-27      121000000.0     144000000.0    -23582400.0   \n",
      "4     000001  2025-02-26      -12659500.0     -27607300.0     14947800.0   \n",
      "\n",
      "   mid_net_inflow  sm_net_inflow       processed_time  \n",
      "0     -29555800.0     -3396800.0  2025-03-05 16:30:23  \n",
      "1      15291700.0    -10697400.0  2025-03-05 16:30:23  \n",
      "2      35873700.0     10107100.0  2025-03-05 16:30:23  \n",
      "3     -47328700.0    -73494900.0  2025-03-05 16:30:23  \n",
      "4      34001900.0    -21342400.0  2025-03-05 16:30:23  \n",
      "\n",
      "数据已保存至 capital_flows_20250305.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import adata\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_recent_capital_flows(stock_list, days=10):\n",
    "    \"\"\"\n",
    "    获取股票列表中各股票最近N个交易日的资金流向数据\n",
    "    \n",
    "    参数:\n",
    "    stock_list (list): 股票代码列表，如 ['000001', '600000']\n",
    "    days (int): 需要获取的交易日天数，默认为10\n",
    "    \n",
    "    返回:\n",
    "    DataFrame: 包含所有股票资金流向的整合数据\n",
    "    \"\"\"\n",
    "    # 初始化结果容器\n",
    "    all_data = []\n",
    "    \n",
    "    # 创建进度条\n",
    "    pbar = tqdm(stock_list, desc='获取资金流向', unit='股')\n",
    "    \n",
    "    for stock_code in pbar:\n",
    "        try:\n",
    "            # 获取原始数据（不指定日期范围）\n",
    "            df = adata.stock.market.get_capital_flow(stock_code=stock_code, start_date = \"2025-02-20\")\n",
    "            \n",
    "            # 空数据检查\n",
    "            if df.empty:\n",
    "                pbar.set_postfix_str(f'{stock_code}: 无数据')\n",
    "                continue\n",
    "                \n",
    "            # 数据预处理\n",
    "            df = df.sort_values('trade_date', ascending=False)\n",
    "            \n",
    "            # 提取最近N个交易日\n",
    "            recent_data = df.head(days).copy()\n",
    "            \n",
    "            # 添加处理标记\n",
    "            recent_data['processed_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            all_data.append(recent_data)\n",
    "            pbar.set_postfix_str(f'{stock_code}: 成功获取{len(recent_data)}天数据')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n股票 {stock_code} 处理失败：{str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 合并数据\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        # 优化列顺序\n",
    "        column_order = ['stock_code', 'trade_date', 'main_net_inflow',\n",
    "                        'max_net_inflow', 'lg_net_inflow', 'mid_net_inflow',\n",
    "                        'sm_net_inflow', 'processed_time']\n",
    "        return final_df[column_order]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == '__main__':\n",
    "    # 示例股票列表（实际可从文件或数据库读取）\n",
    "    sample_stocks = ['000001', '600000', '000002', '600036', '000333']\n",
    "    \n",
    "    # 获取最近10个交易日数据\n",
    "    capital_flows = get_recent_capital_flows(sample_stocks)\n",
    "    \n",
    "    # 结果展示\n",
    "    if not capital_flows.empty:\n",
    "        print(\"\\n最近资金流向数据概览：\")\n",
    "        print(capital_flows.head())\n",
    "        \n",
    "        # 保存到CSV\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "        filename = f\"capital_flows_{timestamp}.csv\"\n",
    "        capital_flows.to_csv(filename, index=False, encoding='utf_8_sig')\n",
    "        print(f\"\\n数据已保存至 {filename}\")\n",
    "    else:\n",
    "        print(\"未获取到有效数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "采集分时数据: 100%|\u001b[32m██████████\u001b[0m| 5/5 [00:09<00:00,  1.91s/股, 000333: 成功获取]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最新分时资金流向数据：\n",
      "    stock_code          trade_time  main_net_inflow  max_net_inflow  \\\n",
      "239     000001 2025-03-05 15:00:00      196392730.0     182941028.0   \n",
      "239     600000 2025-03-05 15:00:00       12463349.0     -11735561.0   \n",
      "239     000002 2025-03-05 15:00:00      -97506560.0     -47637475.0   \n",
      "239     600036 2025-03-05 15:00:00      239051729.0     236489475.0   \n",
      "239     000333 2025-03-05 15:00:00      130989530.0     144331512.0   \n",
      "\n",
      "     lg_net_inflow  mid_net_inflow  sm_net_inflow       processed_time  \n",
      "239     13451702.0    -112132290.0    -84260411.0  2025-03-05 16:25:33  \n",
      "239     24198910.0     -20720583.0      8257239.0  2025-03-05 16:25:35  \n",
      "239    -49869085.0      19594639.0     77911927.0  2025-03-05 16:25:37  \n",
      "239      2562254.0    -313063815.0     74012097.0  2025-03-05 16:25:39  \n",
      "239    -13341982.0    -220586128.0     89596597.0  2025-03-05 16:25:41  \n",
      "\n",
      "数据统计：\n",
      "总记录数：5\n",
      "最新时间范围：2025-03-05 15:00:00 至 2025-03-05 15:00:00\n",
      "\n",
      "数据已保存至 latest_min_capital_flows_20250305_1625.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import adata\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def get_latest_min_capital_flows(stock_list):\n",
    "    \"\"\"\n",
    "    获取各股票最新的分时资金流向数据（最后一个有效记录）\n",
    "    \n",
    "    参数:\n",
    "    stock_list (list): 股票代码列表，如 ['000001', '600000']\n",
    "    \n",
    "    返回:\n",
    "    DataFrame: 包含最新分时数据的整合结果\n",
    "              列结构：[stock_code, trade_time, main_net_inflow, ..., processed_time]\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # 创建带状态显示的进度条\n",
    "    with tqdm(stock_list, desc='采集分时数据', unit='股', colour='green') as pbar:\n",
    "        for stock_code in pbar:\n",
    "            try:\n",
    "                # 获取原始分时数据\n",
    "                df = adata.stock.market.get_capital_flow_min(stock_code=stock_code)\n",
    "                \n",
    "                # 空数据检查\n",
    "                if df.empty:\n",
    "                    pbar.set_postfix_str(f'{stock_code}: 无数据')\n",
    "                    continue\n",
    "                \n",
    "                # 数据验证\n",
    "                required_columns = ['stock_code', 'trade_time', 'main_net_inflow',\n",
    "                                   'max_net_inflow', 'lg_net_inflow', 'mid_net_inflow',\n",
    "                                   'sm_net_inflow']\n",
    "                if not all(col in df.columns for col in required_columns):\n",
    "                    pbar.set_postfix_str(f'{stock_code}: 数据字段缺失')\n",
    "                    continue\n",
    "                \n",
    "                # 获取最新记录（假设数据按时间升序排列）\n",
    "                latest_record = df.iloc[-1].copy()\n",
    "                \n",
    "                # 添加处理元数据\n",
    "                latest_record['processed_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                \n",
    "                results.append(latest_record)\n",
    "                pbar.set_postfix_str(f'{stock_code}: 成功获取')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n股票 {stock_code} 处理异常：{str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # 合并结果\n",
    "    if results:\n",
    "        final_df = pd.DataFrame(results)\n",
    "        # 列顺序标准化\n",
    "        column_order = required_columns + ['processed_time']\n",
    "        return final_df[column_order]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == '__main__':\n",
    "    # 测试用股票列表\n",
    "    test_stocks = ['000001', '600000', '000002', '600036', '000333']\n",
    "    \n",
    "    # 执行数据采集\n",
    "    min_flows = get_latest_min_capital_flows(test_stocks)\n",
    "    \n",
    "    # 结果处理\n",
    "    if not min_flows.empty:\n",
    "        print(\"\\n最新分时资金流向数据：\")\n",
    "        print(min_flows.head())\n",
    "        \n",
    "        # 数据有效性检查\n",
    "        print(\"\\n数据统计：\")\n",
    "        print(f\"总记录数：{len(min_flows)}\")\n",
    "        print(f\"最新时间范围：{min_flows['trade_time'].min()} 至 {min_flows['trade_time'].max()}\")\n",
    "        \n",
    "        # 保存到CSV\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        filename = f\"latest_min_capital_flows_{timestamp}.csv\"\n",
    "        min_flows.to_csv(filename, index=False, encoding='utf_8_sig')\n",
    "        print(f\"\\n数据已保存至 {filename}\")\n",
    "    else:\n",
    "        print(\"未获取到有效数据\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
